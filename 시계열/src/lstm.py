# -*- coding: utf-8 -*-
"""LSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1igTfoIVfrtzY5YXuA-S735U7i98MYiko
"""

import os
import numpy as np
import pandas as pd
import ast
import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader
from sklearn.metrics import accuracy_score, f1_score
import matplotlib.pyplot as plt

# â”€â”€â”€ 1) ìµœì í™”ëœ ì§€í‘œ íŒŒë¼ë¯¸í„° ë¡œë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_selected_indicators(path, ticker):
    df = pd.read_csv(path)
    df = df[df['Ticker'] == ticker]

    if not df['Sharpe_Improved'].any() and not df['MDD_Improved'].any():
        print(f"âš ï¸  {ticker}: Sharpe & MDD ê°œì„  ì—†ìŒ â†’ ê²½í—˜ì  íŒŒë¼ë¯¸í„° ì‚¬ìš©")
        return {
            'sma': [20],
            'ema': [10],
            'rsi': [14, 30],
            'macd': [12, 26, 9],
            'bb': [20, 2]
        }

    selected_indicators = {}
    for _, row in df.iterrows():
        if row['Use'] == 1:
            params_str = row['Params_Opt'] if pd.notnull(row['Params_Opt']) else row['Params_Emp']
            try:
                params = ast.literal_eval(params_str)
            except (ValueError, SyntaxError):
                continue
            selected_indicators[row['Indicator'].lower()] = params

    return selected_indicators

# â”€â”€â”€ 2) ê¸°ìˆ ì  ì§€í‘œ ì‹œê·¸ë„ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def calc_signals(df, params):
    close = df['Close']
    signals = pd.DataFrame(index=df.index)

    if 'sma' in params:
        sma = close.rolling(params['sma'][0]).mean()
        signals['sma'] = np.where(close > sma, -1, 1)

    if 'ema' in params:
        ema = close.ewm(span=params['ema'][0], adjust=False).mean()
        signals['ema'] = np.where(close > ema, -1, 1)

    if 'rsi' in params:
        w, lo = params['rsi']
        delta = close.diff()
        up = delta.clip(lower=0).rolling(w).mean()
        down = -delta.clip(upper=0).rolling(w).mean()
        rsi = 100 - 100 / (1 + up / down)
        sig = pd.Series(0, index=df.index)
        sig[rsi < lo] = -1
        sig[rsi > 100 - lo] = 1
        signals['rsi'] = sig.values

    if 'macd' in params:
        f, s, sl = params['macd']
        macd_line = close.ewm(span=f, adjust=False).mean() - close.ewm(span=s, adjust=False).mean()
        macd_sig = macd_line.ewm(span=sl, adjust=False).mean()
        cross = macd_line - macd_sig
        sig = pd.Series(0, index=df.index)
        sig[(cross.shift(1) < 0) & (cross > 0)] = -1
        sig[(cross.shift(1) > 0) & (cross < 0)] = 1
        signals['macd'] = sig.values

    if 'bb' in params:
        w, ns = params['bb']
        ma = close.rolling(w).mean()
        std = close.rolling(w).std()
        upper = ma + ns * std
        lower = ma - ns * std
        sig = pd.Series(0, index=df.index)
        sig[close < lower] = -1
        sig[close > upper] = 1
        signals['bb'] = sig.values

    signals.fillna(0, inplace=True)
    return signals

# â”€â”€â”€ 3) LSTM ëª¨ë¸ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size=64, num_layers=2):
        super().__init__()
        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,
                            num_layers=num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        out = self.fc(lstm_out[:, -1, :])
        return out.squeeze()

# â”€â”€â”€ 4) ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def create_sequences(X, y, seq_len=10):
    X_seq, y_seq = [], []
    for i in range(len(X) - seq_len):
        X_seq.append(X[i:i+seq_len])
        y_seq.append(y[i+seq_len])
    return np.array(X_seq), np.array(y_seq)

# â”€â”€â”€ 5) í•™ìŠµ ë° í‰ê°€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def train_lstm(X, y, seq_len=10, epochs=50, batch_size=32, lr=1e-3):
    X_seq, y_seq = create_sequences(X, y, seq_len)

    split = int(0.7 * len(X_seq))
    X_train, X_test = X_seq[:split], X_seq[split:]
    y_train, y_test = y_seq[:split], y_seq[split:]

    X_train_t = torch.tensor(X_train, dtype=torch.float32)
    y_train_t = torch.tensor(y_train, dtype=torch.float32)
    X_test_t  = torch.tensor(X_test, dtype=torch.float32)
    y_test_t  = torch.tensor(y_test, dtype=torch.float32)

    train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=batch_size, shuffle=True)

    model = LSTMModel(input_size=X.shape[1])
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    for epoch in range(epochs):
        model.train()
        epoch_loss = 0
        for xb, yb in train_loader:
            optimizer.zero_grad()
            pred = model(xb)
            loss = criterion(pred, yb)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        if (epoch+1) % 10 == 0:
            print(f"[Epoch {epoch+1}] Loss: {epoch_loss/len(train_loader):.5f}")

    model.eval()
    with torch.no_grad():
        y_pred = model(X_test_t).numpy()

    min_len = min(len(y_test), len(y_pred))
    true_dir = np.sign(y_test[:min_len][1:] - y_test[:min_len][:-1])
    pred_dir = np.sign(y_pred[:min_len][1:] - y_pred[:min_len][:-1])

    acc = accuracy_score(true_dir, pred_dir)
    f1 = f1_score(true_dir, pred_dir, average='macro')

    print(f"\nðŸ“Š Final Accuracy: {acc:.4f}")
    print(f"ðŸ“Š Final F1 Score : {f1:.4f}")

    plt.figure(figsize=(10, 4))
    plt.plot(np.arange(min_len), y_test[:min_len], label='True')
    plt.plot(np.arange(min_len), y_pred[:min_len], label='LSTM Pred', alpha=0.7)
    plt.title("LSTM Prediction vs True Target")
    plt.legend()
    plt.tight_layout()
    plt.show()

# â”€â”€â”€ 6) main í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    ticker = 'AAPL'
    proc_dir = '/content/drive/MyDrive/ì‹œê³„ì—´/data/preprocessed'
    targ_dir = '/content/drive/MyDrive/ì‹œê³„ì—´/data/target'
    opt_path = '/content/drive/MyDrive/ì‹œê³„ì—´/reports/optimization_results.csv'

    df_price = pd.read_csv(f'{proc_dir}/{ticker}_processed.csv', parse_dates=['Date'], index_col='Date')
    df_targ  = pd.read_csv(f'{targ_dir}/{ticker}_target.csv', parse_dates=['Date'], index_col='Date')
    df_targ['Target'] = df_targ['triangular_target']

    selected_params = load_selected_indicators(opt_path, ticker)
    signals = calc_signals(df_price, selected_params).values
    y = df_targ['Target'].values

    train_lstm(signals, y, seq_len=10, epochs=50, batch_size=32, lr=1e-3)

!pip install optuna

import optuna
from functools import partial

def objective(trial, X, y):
    # íƒìƒ‰í•  í•˜ì´í¼íŒŒë¼ë¯¸í„°
    hidden_size = trial.suggest_int("hidden_size", 32, 256)
    num_layers = trial.suggest_int("num_layers", 1, 3)
    lr = trial.suggest_loguniform("lr", 1e-5, 1e-2)
    seq_len = trial.suggest_int("seq_len", 5, 20)

    # ì‹œí€€ìŠ¤ ìƒì„±
    X_seq, y_seq = create_sequences(X, y, seq_len)

    # Train/Validation Split
    split = int(0.7 * len(X_seq))
    X_train, X_val = X_seq[:split], X_seq[split:]
    y_train, y_val = y_seq[:split], y_seq[split:]

    # Tensor ë³€í™˜
    X_train_t = torch.tensor(X_train, dtype=torch.float32)
    y_train_t = torch.tensor(y_train, dtype=torch.float32)
    X_val_t = torch.tensor(X_val, dtype=torch.float32)
    y_val_t = torch.tensor(y_val, dtype=torch.float32)

    # ëª¨ë¸ ì´ˆê¸°í™”
    model = LSTMModel(input_size=X.shape[1], hidden_size=hidden_size, num_layers=num_layers)
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    # í•™ìŠµ
    for epoch in range(30):  # ê³ ì •ëœ epoch ìˆ˜
        model.train()
        optimizer.zero_grad()
        output = model(X_train_t)
        loss = criterion(output, y_train_t)
        loss.backward()
        optimizer.step()

    # ì˜ˆì¸¡
    model.eval()
    with torch.no_grad():
        y_pred = model(X_val_t).numpy()
        y_val_np = y_val_t.numpy()

    # ë°©í–¥ì„± í‰ê°€
    min_len = min(len(y_val_np), len(y_pred))
    true_dir = np.sign(y_val_np[:min_len][1:] - y_val_np[:min_len][:-1])
    pred_dir = np.sign(y_pred[:min_len][1:] - y_pred[:min_len][:-1])
    f1 = f1_score(true_dir, pred_dir, average='macro')

    return f1

if __name__ == "__main__":
    # ê¸°ì¡´ê³¼ ë™ì¼í•œ ë°ì´í„° ì²˜ë¦¬
    ticker = 'AAPL'
    proc_dir = '/content/drive/MyDrive/ì‹œê³„ì—´/data/preprocessed'
    targ_dir = '/content/drive/MyDrive/ì‹œê³„ì—´/data/target'
    opt_path = '/content/drive/MyDrive/ì‹œê³„ì—´/reports/optimization_results.csv'

    df_price = pd.read_csv(f'{proc_dir}/{ticker}_processed.csv', parse_dates=['Date'], index_col='Date')
    df_targ  = pd.read_csv(f'{targ_dir}/{ticker}_target.csv', parse_dates=['Date'], index_col='Date')
    df_targ['Target'] = df_targ['triangular_target']

    selected_params = load_selected_indicators(opt_path, ticker)
    signals = calc_signals(df_price, selected_params).values
    y = df_targ['Target'].values

    # Optuna ìˆ˜í–‰
    study = optuna.create_study(direction='maximize')
    study.optimize(partial(objective, X=signals, y=y), n_trials=50)

    print("\nâœ¨ Best trial:")
    print(study.best_trial.params)

    best = study.best_trial.params
    print("ìž¬í•™ìŠµ ì¤‘...")

    # ì‹œí€€ìŠ¤ ìž¬ìƒì„±
    X_seq, y_seq = create_sequences(signals, y, seq_len=best['seq_len'])
    split = int(0.7 * len(X_seq))
    X_train, X_test = X_seq[:split], X_seq[split:]
    y_train, y_test = y_seq[:split], y_seq[split:]

    X_train_t = torch.tensor(X_train, dtype=torch.float32)
    y_train_t = torch.tensor(y_train, dtype=torch.float32)
    X_test_t  = torch.tensor(X_test, dtype=torch.float32)
    y_test_t  = torch.tensor(y_test, dtype=torch.float32)

    model = LSTMModel(input_size=signals.shape[1], hidden_size=best['hidden_size'], num_layers=best['num_layers'])
    optimizer = torch.optim.Adam(model.parameters(), lr=best['lr'])
    criterion = nn.MSELoss()

    for epoch in range(50):
        model.train()
        optimizer.zero_grad()
        output = model(X_train_t)
        loss = criterion(output, y_train_t)
        loss.backward()
        optimizer.step()

    model.eval()
    with torch.no_grad():
        y_pred = model(X_test_t).numpy()
        y_test_np = y_test_t.numpy()

    min_len = min(len(y_test_np), len(y_pred))
    true_dir = np.sign(y_test_np[:min_len][1:] - y_test_np[:min_len][:-1])
    pred_dir = np.sign(y_pred[:min_len][1:] - y_pred[:min_len][:-1])
    acc = accuracy_score(true_dir, pred_dir)
    f1 = f1_score(true_dir, pred_dir, average='macro')
    print(f"\nâœ… ìµœì¢… Accuracy: {acc:.4f}")
    print(f"âœ… ìµœì¢… F1 Score : {f1:.4f}")

    # ì‹œê°í™”
    plt.figure(figsize=(10, 4))
    plt.plot(np.arange(min_len), y_test_np[:min_len], label='True')
    plt.plot(np.arange(min_len), y_pred[:min_len], label='LSTM Pred', alpha=0.7)
    plt.title("LSTM Prediction (Best Trial)")
    plt.legend()
    plt.tight_layout()
    plt.show()

import numpy as np
import pandas as pd

def backtest_performance(pred_signal, close_prices, transaction_cost=0.001):
    """
    pred_signal: np.array of {-1, 0, 1}
    close_prices: np.array of close prices (same length)
    """
    pred_signal = np.array(pred_signal)
    close_prices = np.array(close_prices)

    # ìˆ˜ìµë¥  ê³„ì‚°
    returns = np.diff(close_prices) / close_prices[:-1]
    signal = pred_signal[:-1]  # ë‹¤ìŒ ë‚  ìˆ˜ìµë¥ ì— ì˜¤ëŠ˜ ì‹œê·¸ë„ ì ìš©
    strat_ret = signal * returns - transaction_cost * np.abs(np.diff(signal, prepend=0))

    # ëˆ„ì  ìˆ˜ìµë¥ 
    cum_ret = np.cumprod(1 + strat_ret) - 1

    # ìƒ¤í”„ì§€ìˆ˜ (ì—°ìœ¨í™” ê¸°ì¤€ ê°€ì •: 252 ê±°ëž˜ì¼)
    excess_ret = strat_ret - 0.0001  # ë¬´ìœ„í—˜ ìˆ˜ìµë¥  ëŒ€ì²´ê°’
    sharpe = np.mean(excess_ret) / (np.std(excess_ret) + 1e-8) * np.sqrt(252)

    # MDD
    cum_val = np.cumprod(1 + strat_ret)
    peak = np.maximum.accumulate(cum_val)
    drawdown = (cum_val - peak) / peak
    mdd = np.min(drawdown)

    return {
        "Cumulative Return": cum_ret[-1],
        "Sharpe Ratio": sharpe,
        "MDD": mdd
    }

def buy_hold_performance(close_prices):
    returns = np.diff(close_prices) / close_prices[:-1]
    strat_ret = returns  # í•­ìƒ ë³´ìœ 
    cum_ret = np.cumprod(1 + strat_ret) - 1
    sharpe = np.mean(strat_ret) / (np.std(strat_ret) + 1e-8) * np.sqrt(252)

    cum_val = np.cumprod(1 + strat_ret)
    peak = np.maximum.accumulate(cum_val)
    drawdown = (cum_val - peak) / peak
    mdd = np.min(drawdown)

    return {
        "Cumulative Return": cum_ret[-1],
        "Sharpe Ratio": sharpe,
        "MDD": mdd
    }

# ì‹ í˜¸ ìƒì„±: ì˜ˆì¸¡ ìˆ˜ìµë¥  > 0 â†’ ë§¤ìˆ˜, < 0 â†’ ë§¤ë„
pred_signal = np.sign(y_pred[:min_len])  # ì˜ˆì¸¡ ê¸°ë°˜ ì‹ í˜¸
close = df_price['Close'].values[-len(y_test):]  # ì˜ˆì¸¡ êµ¬ê°„ì˜ ì¢…ê°€

bt_lstm = backtest_performance(pred_signal, close[:min_len])
bt_bnh  = buy_hold_performance(close[:min_len])

print("\nðŸ“ˆ [LSTM ì „ëžµ]")
for k, v in bt_lstm.items():
    print(f"{k}: {v:.4f}")

print("\nðŸ“Š [Buy & Hold ì „ëžµ]")
for k, v in bt_bnh.items():
    print(f"{k}: {v:.4f}")

import matplotlib.pyplot as plt
import numpy as np

def plot_cumulative_returns(pred_signal, close_prices, title="Cumulative Return Comparison", transaction_cost=0.001):
    """
    pred_signal: ì˜ˆì¸¡ ì‹œê·¸ë„ (np.array), {-1, 0, 1}
    close_prices: ì¢…ê°€ ì‹œê³„ì—´ (np.array)
    """

    pred_signal = np.array(pred_signal)
    close_prices = np.array(close_prices)

    # ìˆ˜ìµë¥  ê³„ì‚°
    returns = np.diff(close_prices) / close_prices[:-1]

    # ì˜ˆì¸¡ ì „ëžµ ìˆ˜ìµë¥ 
    signal = pred_signal[:-1]
    strategy_returns = signal * returns - transaction_cost * np.abs(np.diff(signal, prepend=0))
    cumulative_strategy = np.cumprod(1 + strategy_returns)

    # Buy & Hold ìˆ˜ìµë¥ 
    buy_hold_returns = returns
    cumulative_bnh = np.cumprod(1 + buy_hold_returns)

    # ì‹œê°í™”
    plt.figure(figsize=(12, 6))
    plt.plot(cumulative_strategy, label='ðŸ“ˆ Predictive Strategy')
    plt.plot(cumulative_bnh, label='ðŸ’¼ Buy & Hold', linestyle='--')
    plt.title(title)
    plt.xlabel("Time Steps (Days)")
    plt.ylabel("Cumulative Return")
    plt.grid(True, alpha=0.3)
    plt.legend()
    plt.tight_layout()
    plt.show()

# ì˜ˆì¸¡ ê²°ê³¼ë¡œ ì‹œê·¸ë„ ìƒì„±
pred_signal = np.sign(y_pred[:min_len])
close = df_price['Close'].values[-len(y_test):]  # test ì‹œì  ì¢…ê°€
close_cut = close[:min_len]

# ì‹œê°í™” í˜¸ì¶œ
plot_cumulative_returns(pred_signal, close_cut, title=f"{ticker} - LSTM vs Buy & Hold")